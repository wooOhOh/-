{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:39:37.447969800Z",
     "start_time": "2024-06-05T09:39:37.441314300Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整训练集大小是 (3253, 7)\n",
      "完整测试集大小是 (120, 6)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"数据集加载\"\"\"\n",
    "train_file_path = \"../数据/清理后的数据/clean_train.csv\"\n",
    "train = pd.read_csv(train_file_path)\n",
    "test_file_path = \"../数据/清理后的数据/clean_test.csv\"\n",
    "test = pd.read_csv(test_file_path)\n",
    "print(\"完整训练集大小是 {}\".format(train.shape))\n",
    "print(\"完整测试集大小是 {}\".format(test.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:39:39.701137400Z",
     "start_time": "2024-06-05T09:39:39.686479700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (3373, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     cycle  capacity  resistance         CCCT         CVCT\n0      1.0  1.126385    0.094009  6613.059052  2251.498033\n1      2.0  1.126160    0.091661  6612.402800  2231.967052\n2      3.0  1.125966    0.094649  6608.560673  2228.216959\n3      4.0  1.118508    0.091413  6604.732222  2247.561061\n4      5.0  1.117210    0.091413  6629.211049  2077.692393\n..     ...       ...         ...          ...          ...\n995  385.0  0.969525    0.093080  5500.193208  2503.694372\n996  386.0  0.978220    0.088546  5475.849651  2541.521603\n997  387.0  0.978875    0.087654  5547.057277  2366.262200\n998  388.0  0.969841    0.090171  5607.496941  2322.231989\n999  389.0  0.962900    0.092439  5598.935383  2359.900566\n\n[1000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cycle</th>\n      <th>capacity</th>\n      <th>resistance</th>\n      <th>CCCT</th>\n      <th>CVCT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.126385</td>\n      <td>0.094009</td>\n      <td>6613.059052</td>\n      <td>2251.498033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.126160</td>\n      <td>0.091661</td>\n      <td>6612.402800</td>\n      <td>2231.967052</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>1.125966</td>\n      <td>0.094649</td>\n      <td>6608.560673</td>\n      <td>2228.216959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>1.118508</td>\n      <td>0.091413</td>\n      <td>6604.732222</td>\n      <td>2247.561061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>1.117210</td>\n      <td>0.091413</td>\n      <td>6629.211049</td>\n      <td>2077.692393</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>385.0</td>\n      <td>0.969525</td>\n      <td>0.093080</td>\n      <td>5500.193208</td>\n      <td>2503.694372</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>386.0</td>\n      <td>0.978220</td>\n      <td>0.088546</td>\n      <td>5475.849651</td>\n      <td>2541.521603</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>387.0</td>\n      <td>0.978875</td>\n      <td>0.087654</td>\n      <td>5547.057277</td>\n      <td>2366.262200</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>388.0</td>\n      <td>0.969841</td>\n      <td>0.090171</td>\n      <td>5607.496941</td>\n      <td>2322.231989</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>389.0</td>\n      <td>0.962900</td>\n      <td>0.092439</td>\n      <td>5598.935383</td>\n      <td>2359.900566</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.SoH.values\n",
    "dataset_df = pd.concat((train, test)).reset_index(drop=True)\n",
    "dataset_df.drop(['SoH'], axis=1, inplace=True)\n",
    "dataset_df.drop(['CS_Name'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(dataset_df.shape))\n",
    "dataset_df.head(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:39:42.744659200Z",
     "start_time": "2024-06-05T09:39:42.733824700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# \"\"\"对CS_name进行独热编码\"\"\"\n",
    "# dataset_df = pd.get_dummies(dataset_df)\n",
    "# dataset_df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:39:16.089949100Z",
     "start_time": "2024-06-05T09:39:16.059165600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "     cycle  capacity  resistance         CCCT         CVCT       SoH\n0      1.0  1.126385    0.094009  6613.059052  2251.498033  0.825175\n1      2.0  1.126160    0.091661  6612.402800  2231.967052  0.815965\n2      3.0  1.125966    0.094649  6608.560673  2228.216959  0.815977\n3      4.0  1.118508    0.091413  6604.732222  2247.561061  0.825194\n4      5.0  1.117210    0.091413  6629.211049  2077.692393  0.806900\n..     ...       ...         ...          ...          ...       ...\n995  385.0  0.969525    0.093080  5500.193208  2503.694372  0.733665\n996  386.0  0.978220    0.088546  5475.849651  2541.521603  0.715319\n997  387.0  0.978875    0.087654  5547.057277  2366.262200  0.724505\n998  388.0  0.969841    0.090171  5607.496941  2322.231989  0.715312\n999  389.0  0.962900    0.092439  5598.935383  2359.900566  0.715299\n\n[1000 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cycle</th>\n      <th>capacity</th>\n      <th>resistance</th>\n      <th>CCCT</th>\n      <th>CVCT</th>\n      <th>SoH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.126385</td>\n      <td>0.094009</td>\n      <td>6613.059052</td>\n      <td>2251.498033</td>\n      <td>0.825175</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.126160</td>\n      <td>0.091661</td>\n      <td>6612.402800</td>\n      <td>2231.967052</td>\n      <td>0.815965</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>1.125966</td>\n      <td>0.094649</td>\n      <td>6608.560673</td>\n      <td>2228.216959</td>\n      <td>0.815977</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>1.118508</td>\n      <td>0.091413</td>\n      <td>6604.732222</td>\n      <td>2247.561061</td>\n      <td>0.825194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>1.117210</td>\n      <td>0.091413</td>\n      <td>6629.211049</td>\n      <td>2077.692393</td>\n      <td>0.806900</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>385.0</td>\n      <td>0.969525</td>\n      <td>0.093080</td>\n      <td>5500.193208</td>\n      <td>2503.694372</td>\n      <td>0.733665</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>386.0</td>\n      <td>0.978220</td>\n      <td>0.088546</td>\n      <td>5475.849651</td>\n      <td>2541.521603</td>\n      <td>0.715319</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>387.0</td>\n      <td>0.978875</td>\n      <td>0.087654</td>\n      <td>5547.057277</td>\n      <td>2366.262200</td>\n      <td>0.724505</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>388.0</td>\n      <td>0.969841</td>\n      <td>0.090171</td>\n      <td>5607.496941</td>\n      <td>2322.231989</td>\n      <td>0.715312</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>389.0</td>\n      <td>0.962900</td>\n      <td>0.092439</td>\n      <td>5598.935383</td>\n      <td>2359.900566</td>\n      <td>0.715299</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"模型构建与评估\"\"\"\n",
    "\n",
    "\"\"\"训练测试集分隔\"\"\"\n",
    "clean_train = dataset_df[:ntrain]\n",
    "clean_test = dataset_df[ntrain:]\n",
    "clean_train = pd.concat([clean_train, pd.Series(y_train, name='SoH')], axis=1)\n",
    "clean_train.shape,clean_test.shape\n",
    "clean_train.head(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:39:48.223800300Z",
     "start_time": "2024-06-05T09:39:48.212977500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2602, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.655701\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2602, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.659202\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2602, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.659821\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.655473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.715383\n",
      "lgb rmse score: 0.0381, rmse std: 0.0530\n",
      "xgb rmse score: 0.0373, rmse std: 0.0515\n",
      "ridge rmse score: 0.0234, rmse std: 0.0209\n",
      "svr rmse score: 0.0939, rmse std: 0.0827\n",
      "gbr rmse score: 0.0383, rmse std: 0.0543\n",
      "rf rmse score: 0.0388, rmse std: 0.0524\n"
     ]
    },
    {
     "data": {
      "text/plain": "               ridge       xgb       lgb       gbr        rf       svr\nrmse_score  0.023392  0.037285  0.038124  0.038336  0.038835  0.093931\nrmse_std    0.020946  0.051467  0.052990  0.054300  0.052431  0.082692",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ridge</th>\n      <th>xgb</th>\n      <th>lgb</th>\n      <th>gbr</th>\n      <th>rf</th>\n      <th>svr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>rmse_score</th>\n      <td>0.023392</td>\n      <td>0.037285</td>\n      <td>0.038124</td>\n      <td>0.038336</td>\n      <td>0.038835</td>\n      <td>0.093931</td>\n    </tr>\n    <tr>\n      <th>rmse_std</th>\n      <td>0.020946</td>\n      <td>0.051467</td>\n      <td>0.052990</td>\n      <td>0.054300</td>\n      <td>0.052431</td>\n      <td>0.082692</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"模型训练与预测\"\"\"\n",
    "# 定义评价指标\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "X = clean_train.drop(columns='SoH')\n",
    "y = clean_train['SoH']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "# 定义交叉验证模式\n",
    "kf = KFold(n_splits=10, random_state=50, shuffle=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# 建立基线模型\n",
    "lgb = LGBMRegressor(objective='regression', random_state=50)\n",
    "xgb = XGBRegressor(objective='reg:squarederror',random_state=50)\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(cv=kf))\n",
    "svr = make_pipeline(RobustScaler(), SVR())\n",
    "gbr = GradientBoostingRegressor(random_state=50)\n",
    "rf = RandomForestRegressor(random_state=50)\n",
    "scores = {}\n",
    "# 基线模型评估\n",
    "models = [lgb, xgb, ridge, svr, gbr, rf]\n",
    "model_names = ['lgb','xgb','ridge','svr','gbr','rf']\n",
    "for i, model in enumerate(models):\n",
    "    score = rmse_cv(model)\n",
    "    print('{} rmse score: {:.4f}, rmse std: {:.4f}'.format(model_names[i], score.mean(), score.std()))\n",
    "    scores[model_names[i]] = (score.mean(), score.std())\n",
    "\n",
    "rmse_df = pd.DataFrame(scores, index=['rmse_score','rmse_std'])\n",
    "rmse_df.sort_values('rmse_score', axis=1, inplace=True)\n",
    "rmse_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:40:06.014694200Z",
     "start_time": "2024-06-05T09:39:53.764001300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.669849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.670318\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.671980\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.670341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.669567\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.668762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2049, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.671418\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2050, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.671857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2050, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.669776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2050, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.671276\n",
      "lgb is done.\n",
      "xgb is done.\n",
      "ridge is done.\n",
      "svr is done.\n",
      "gbr is done.\n",
      "rf is done.\n",
      "----stacked_train----\n",
      "            lgb       xgb     ridge       svr       gbr        rf    y_true\n",
      "0     0.451221  0.444128  0.452390  0.476011  0.444196  0.440871  0.440112\n",
      "1     0.571325  0.570832  0.565531  0.628575  0.572434  0.573336  0.577583\n",
      "2     0.726417  0.725527  0.719200  0.691803  0.724968  0.724448  0.724342\n",
      "3     0.733380  0.735296  0.729884  0.706187  0.733299  0.731477  0.733288\n",
      "4     0.777156  0.775192  0.783686  0.708285  0.777130  0.777024  0.779523\n",
      "...        ...       ...       ...       ...       ...       ...       ...\n",
      "2272  0.398851  0.395961  0.420487  0.418880  0.405978  0.394669  0.394146\n",
      "2273  0.760098  0.760364  0.748911  0.714310  0.763583  0.762277  0.751800\n",
      "2274  0.679510  0.681297  0.676965  0.660561  0.675635  0.679112  0.678431\n",
      "2275  0.400753  0.401242  0.410347  0.412720  0.401163  0.400699  0.384971\n",
      "2276  0.774494  0.777254  0.786973  0.700393  0.776438  0.775918  0.770136\n",
      "\n",
      "[2277 rows x 7 columns]\n",
      "----stacked_test----\n",
      "           lgb       xgb     ridge       svr       gbr        rf\n",
      "0    0.743298  0.743586  0.757251  0.704559  0.739229  0.746144\n",
      "1    0.711994  0.712914  0.707805  0.685224  0.712868  0.711886\n",
      "2    0.361554  0.365364  0.384936  0.383504  0.353026  0.353460\n",
      "3    0.712836  0.713586  0.725174  0.696364  0.713705  0.713408\n",
      "4    0.647064  0.646527  0.647401  0.648669  0.647908  0.646705\n",
      "..        ...       ...       ...       ...       ...       ...\n",
      "971  0.392646  0.389399  0.380725  0.407645  0.384017  0.388279\n",
      "972  0.612364  0.612047  0.620661  0.642458  0.610949  0.614316\n",
      "973  0.656074  0.654655  0.648938  0.667101  0.659532  0.656021\n",
      "974  0.775663  0.774544  0.777012  0.716482  0.773893  0.774428\n",
      "975  0.689469  0.689363  0.698370  0.681604  0.690560  0.689613\n",
      "\n",
      "[976 rows x 6 columns]\n",
      "0.007084286098310534\n"
     ]
    }
   ],
   "source": [
    "\"\"\"模型Stacking\"\"\"\n",
    "class StackingRegressor(object):\n",
    "\n",
    "    def __init__(self, fir_models, fir_model_names, sec_model, cv):\n",
    "        # 第一层的基模型\n",
    "        self.fir_models = fir_models\n",
    "        self.fir_model_names = fir_model_names\n",
    "        # 第二层用来预测结果的模型\n",
    "        self.sec_model = sec_model\n",
    "        # 交叉验证模式，必须为k_fold对象\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit_predict(self, X, y, test):    # X,y,test必须为DataFrame\n",
    "        # 创建空DataFrame\n",
    "        stacked_train = pd.DataFrame()\n",
    "        stacked_test = pd.DataFrame()\n",
    "        # 初始化折数\n",
    "        n_fold = 0\n",
    "\n",
    "        # 遍历每个模型，做交叉验证\n",
    "        for i, model in enumerate(self.fir_models):\n",
    "            # 初始化stacked_train\n",
    "            stacked_train[self.fir_model_names[i]] = np.zeros(shape=(X.shape[0], ))\n",
    "\n",
    "            #遍历每一折交叉验证\n",
    "            for train_index, valid_index in self.cv.split(X):\n",
    "                # 初始化stacked_test\n",
    "                n_fold += 1\n",
    "                stacked_test[self.fir_model_names[i] + str(n_fold)] = np.zeros(shape=(test.shape[0], ))\n",
    "\n",
    "                # 划分数据集\n",
    "                X_train, y_train = X.iloc[train_index, :], y.iloc[train_index]\n",
    "                X_valid, y_valid = X.iloc[valid_index, :], y.iloc[valid_index]\n",
    "\n",
    "                # 训练模型并预测结果\n",
    "                model.fit(X_train, y_train)\n",
    "                stacked_train.loc[valid_index, self.fir_model_names[i]] = model.predict(X_valid)\n",
    "                stacked_test.loc[:, self.fir_model_names[i] + str(n_fold)] = model.predict(test)\n",
    "            print('{} is done.'.format(self.fir_model_names[i]))\n",
    "\n",
    "        # stacked_train加上真实值标签\n",
    "        y.reset_index(drop=True, inplace=True)\n",
    "        stacked_train['y_true'] = y\n",
    "\n",
    "        # 计算stacked_test中每个模型预测结果的平均值\n",
    "        for i, model_name in enumerate(self.fir_model_names):\n",
    "            stacked_test[model_name] = stacked_test.iloc[:, :10].mean(axis=1)\n",
    "            stacked_test.drop(stacked_test.iloc[:, :10], axis=1, inplace=True)\n",
    "\n",
    "        # 打印stacked_train和stacked_test\n",
    "        print('----stacked_train----\\n', stacked_train)\n",
    "        print('----stacked_test----\\n', stacked_test)\n",
    "\n",
    "        # 用sec_model预测结果\n",
    "        self.sec_model.fit(stacked_train.drop(columns='y_true'), stacked_train['y_true'])\n",
    "        y_pred = self.sec_model.predict(stacked_test)\n",
    "        return y_pred\n",
    "\n",
    "sr = StackingRegressor(models, model_names, ridge, kf)\n",
    "stacking_pred = sr.fit_predict(Xtrain, ytrain, Xtest)\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return rmse\n",
    "\n",
    "stacking_score = rmse(ytest, stacking_pred)\n",
    "print(stacking_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T09:40:37.987137100Z",
     "start_time": "2024-06-05T09:40:17.697628900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"模型均值融合\"\"\"\n",
    "def blending(X, y, test):\n",
    "    lgb.fit(X, y)\n",
    "    lgb_pred = lgb.predict(test)\n",
    "\n",
    "    xgb.fit(X, y)\n",
    "    xgb_pred = xgb.predict(test)\n",
    "\n",
    "    ridge.fit(X, y)\n",
    "    ridge_pred = ridge.predict(test)\n",
    "\n",
    "    svr.fit(X, y)\n",
    "    svr_pred = svr.predict(test)\n",
    "\n",
    "    gbr.fit(X, y)\n",
    "    gbr_pred = gbr.predict(test)\n",
    "\n",
    "    rf.fit(X, y)\n",
    "    rf_pred = rf.predict(test)\n",
    "\n",
    "\n",
    "    # 加权求和\n",
    "    # blended_pred = (0.05* lgb_pred +\n",
    "    #                 0.15 * xgb_pred +\n",
    "    #                 0.6 * ridge_pred +\n",
    "    #                 0.0 * svr_pred +\n",
    "    #                 0.05 * gbr_pred +\n",
    "    #                 0.15 * rf_pred )\n",
    "\n",
    "    blended_pred=ridge_pred\n",
    "    return blended_pred\n",
    "def rmse(y, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return rmse\n",
    "blended_pred = blending(Xtrain, ytrain, Xtest)\n",
    "blending_score = rmse(ytest, blended_pred)\n",
    "print(blending_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"结果注册\"\"\"\n",
    "sr = StackingRegressor(models, model_names, ridge, kf)\n",
    "sample_submission_df = pd.read_csv('../数据/清理后的数据/submission_example.csv')\n",
    "sample_submission_df['result'] = sr.fit_predict(X, y, clean_test)\n",
    "sample_submission_df.to_csv('../结果/submission_3.csv', index=False)\n",
    "sample_submission_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
